{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ea26c4d5500792681b2cebd9d2703971364afca0312a11ff0d00d5b10c0158d8",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Example Notebook for the Psypypeline\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import the module and setup a pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\hulin\\anaconda3\\lib\\site-packages\\bids\\layout\\models.py:148: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n  warnings.warn(\"The 'extension' entity currently excludes the leading dot ('.'). \"\n"
     ]
    }
   ],
   "source": [
    "from psypypeline.psypypeline import Pipeline\n",
    "pipeline = Pipeline(name=\"TestPipeline\", root=\"example\")"
   ]
  },
  {
   "source": [
    "This loads everything as specified in pipeline.json, which must lie in *<root\\>/derivatives/<name\\>*\n",
    "In pipeline.json, one can specify processes (their name, the script in which they are stored and a version of their name which will be used for filenames) and masks (their name and the nii(.gz) file in which they are stored).\n",
    "the above code loads all of this into memory.\n",
    "You can call `pipeline.processes` or `pipeline.masks` and compare the output to the content of the *pipeline.json* or the folder (*masks*) or python script (*processes.py** where they *re stored."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'csf': nltools.data.brain_data.Brain_Data(data=(238955,), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[]),\n",
       " 'rois': nltools.data.brain_data.Brain_Data(data=(238955,), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pipeline.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'denoise': <psypypeline.psypypeline.Process at 0x1f009094af0>,\n",
       " 'smooth': <psypypeline.psypypeline.Process at 0x1f009094100>,\n",
       " 'EVcentrality': <psypypeline.psypypeline.Process at 0x1f009081370>}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pipeline.processes"
   ]
  },
  {
   "source": [
    "Here we see a new class: `Processes`. Calling the `__dict__` of one of the processes, tells us more about their content:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'key': 'denoised',\n",
       " 'process': <function processes.denoise(pipeline, sub, data, global_spike_cutoff=3, diff_spike_cutoff=3)>,\n",
       " 'readable': <function psypypeline.psypypeline.Process.__init__.<locals>.<lambda>(args)>}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "pipeline.processes[\"denoise\"].__dict__"
   ]
  },
  {
   "source": [
    "## Load data using the pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now, loading the data is easy:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...loading the unprocessed file of subject S01\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nltools.data.brain_data.Brain_Data(data=(16, 238955), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "pipeline.load_data(sub=\"S01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...found sub-S01_smoothed_bold.nii.gz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nltools.data.brain_data.Brain_Data(data=(16, 238955), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pipeline.load_data(sub=\"S01\", smooth={})"
   ]
  },
  {
   "source": [
    "As we can see here, just supplying the name of a subject loads the unprocesses file. Additionally supplying keywords like `smooth` applies processes from `pipeline.processes` to them, in the order of appearance. As you can see, no key is supplied to the keyword, which means that the process will run with the default parameters. We can specify the parameters by supplying *<key\\>-<value\\>* pairs in the dictionary. But how do we know which parameters are allowed (apart from checking our own code again)?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function processes.smooth(pipeline, sub, data, fwhm=6)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pipeline.processes[\"smooth\"].process"
   ]
  },
  {
   "source": [
    "So smoothing data with a different kernel looks like this: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...found sub-S01_smoothed-{fwhm-3}_bold.nii.gz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nltools.data.brain_data.Brain_Data(data=(16, 238955), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pipeline.load_data(\"S01\", smooth={\"fwhm\": 3})"
   ]
  },
  {
   "source": [
    "Note that, if you run of the `load_data` cells multiple times, it speeds up considerably and there is less output. That is because, if not specified otherwise, the loading process first checks if already applied this process and stored it. You can change that an other behavior of the function. Look at the docstring to find out more."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msub\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Brain_Data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnltools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBrain_Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Load data from pipeline.root/derivatives/pipeline.name and/or applies processes from\n",
      "pipeline.processes to it.\n",
      "By default, first checks wether the processes have been applied and saved before and \n",
      "then loads them. By default, saves all the intermediate steps\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "sub : str\n",
      "    Name of the subject to load the process from.\n",
      "return_type : str, optional\n",
      "    Type the return value. Must be one of \"path\", \"Brain_Data\". If \"path\" and write=\"none\" and file does not exist,\n",
      "    throws an Error, as path does not exist. By default \"Brain_Data\"\n",
      "write : str, optional\n",
      "    Wether to save the intermediate and the last step when applying processes. Must be one of \"none\" (no step is saved),\n",
      "    \"main\" (only endresult is saved) or \"all\" (all intermediate steps are saved). By default \"all\"\n",
      "force : str, optional\n",
      "    Wether to apply processes even though a file of this already exists. Must be one of \"none\", \"main\", \"all\" (see above).\n",
      "    By default \"none\"\n",
      "verbose : bool, optional\n",
      "    Wether to be verbose, by default True\n",
      "reload : bool, optional\n",
      "    Wether to reload the pipeline.layout after writing a file. Only recommended if computing multiple independend processes.\n",
      "    Then, afterwards, should be reloaded by hand (call `pipeline.layout = BIDSLayout(pipeline.root)`\n",
      "    , by default True\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Brain_Data, str\n",
      "    (Un)Processed data or path to where the data is stored\n",
      "\n",
      "Raises\n",
      "------\n",
      "TypeError\n",
      "    If wrong return_type is supplied\n",
      "FileNotFoundError\n",
      "    If subject is not found\n",
      "KeyError\n",
      "    If an unknown process is supplied\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\hulin\\documents\\uni\\20wise\\masterarbeit\\psypypeline\\psypypeline\\psypypeline.py\n",
      "\u001b[1;31mType:\u001b[0m      method\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "?pipeline.load_data"
   ]
  }
 ]
}